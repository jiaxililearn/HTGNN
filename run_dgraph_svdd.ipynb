{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from model.model import HTGNN, NodePredictor\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from sklearn import metrics\n",
    "\n",
    "dgl.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:1')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_feats, _ = load_graphs('./data/dgraph/train_feats.bin')\n",
    "valid_feats, _ = load_graphs('./data/dgraph/valid_feats.bin')\n",
    "test_feats, _ = load_graphs('./data/dgraph/test_feats.bin')\n",
    "\n",
    "train_labels = torch.load(\"./data/dgraph/train_labels.pt\")\n",
    "valid_labels = torch.load(\"./data/dgraph/valid_labels.pt\")\n",
    "test_labels = torch.load(\"./data/dgraph/test_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes={'A': 521, 'B': 916, 'C': 307},\n",
       "       num_edges={('A', '10_t1', 'A'): 42, ('A', '10_t1', 'B'): 46, ('A', '10_t1', 'C'): 32, ('A', '11_t1', 'A'): 10, ('A', '11_t1', 'B'): 15, ('A', '11_t1', 'C'): 9, ('A', '9_t1', 'A'): 15, ('A', '9_t1', 'B'): 58, ('A', '9_t1', 'C'): 14, ('B', '10_t1', 'A'): 64, ('B', '10_t1', 'B'): 142, ('B', '10_t1', 'C'): 78, ('B', '11_t1', 'A'): 23, ('B', '11_t1', 'B'): 72, ('B', '11_t1', 'C'): 17, ('B', '9_t1', 'A'): 89, ('B', '9_t1', 'B'): 18, ('B', '9_t1', 'C'): 26, ('C', '10_t1', 'A'): 23, ('C', '10_t1', 'B'): 25, ('C', '10_t1', 'C'): 12, ('C', '11_t1', 'A'): 1, ('C', '11_t1', 'B'): 6, ('C', '11_t1', 'C'): 6, ('C', '9_t1', 'A'): 21, ('C', '9_t1', 'B'): 11, ('C', '9_t1', 'C'): 5},\n",
       "       metagraph=[('A', 'A', '10_t1'), ('A', 'A', '11_t1'), ('A', 'A', '9_t1'), ('A', 'B', '10_t1'), ('A', 'B', '11_t1'), ('A', 'B', '9_t1'), ('A', 'C', '10_t1'), ('A', 'C', '11_t1'), ('A', 'C', '9_t1'), ('B', 'A', '10_t1'), ('B', 'A', '11_t1'), ('B', 'A', '9_t1'), ('B', 'B', '10_t1'), ('B', 'B', '11_t1'), ('B', 'B', '9_t1'), ('B', 'C', '10_t1'), ('B', 'C', '11_t1'), ('B', 'C', '9_t1'), ('C', 'A', '10_t1'), ('C', 'A', '11_t1'), ('C', 'A', '9_t1'), ('C', 'B', '10_t1'), ('C', 'B', '11_t1'), ('C', 'B', '9_t1'), ('C', 'C', '10_t1'), ('C', 'C', '11_t1'), ('C', 'C', '9_t1')]),\n",
       " Graph(num_nodes={'A': 126, 'B': 178, 'C': 78},\n",
       "       num_edges={('A', '10_t1', 'A'): 10, ('A', '10_t1', 'B'): 7, ('A', '10_t1', 'C'): 5, ('A', '11_t1', 'B'): 4, ('A', '11_t1', 'C'): 2, ('A', '9_t1', 'A'): 5, ('A', '9_t1', 'B'): 9, ('A', '9_t1', 'C'): 3, ('B', '10_t1', 'A'): 18, ('B', '10_t1', 'B'): 20, ('B', '10_t1', 'C'): 21, ('B', '11_t1', 'A'): 4, ('B', '11_t1', 'B'): 14, ('B', '11_t1', 'C'): 3, ('B', '9_t1', 'A'): 29, ('B', '9_t1', 'B'): 1, ('B', '9_t1', 'C'): 3, ('C', '10_t1', 'A'): 8, ('C', '10_t1', 'B'): 7, ('C', '10_t1', 'C'): 7, ('C', '11_t1', 'A'): 1, ('C', '11_t1', 'B'): 1, ('C', '9_t1', 'A'): 6, ('C', '9_t1', 'B'): 2, ('C', '9_t1', 'C'): 1},\n",
       "       metagraph=[('A', 'A', '10_t1'), ('A', 'A', '9_t1'), ('A', 'B', '10_t1'), ('A', 'B', '11_t1'), ('A', 'B', '9_t1'), ('A', 'C', '10_t1'), ('A', 'C', '11_t1'), ('A', 'C', '9_t1'), ('B', 'A', '10_t1'), ('B', 'A', '11_t1'), ('B', 'A', '9_t1'), ('B', 'B', '10_t1'), ('B', 'B', '11_t1'), ('B', 'B', '9_t1'), ('B', 'C', '10_t1'), ('B', 'C', '11_t1'), ('B', 'C', '9_t1'), ('C', 'A', '10_t1'), ('C', 'A', '11_t1'), ('C', 'A', '9_t1'), ('C', 'B', '10_t1'), ('C', 'B', '11_t1'), ('C', 'B', '9_t1'), ('C', 'C', '10_t1'), ('C', 'C', '9_t1')]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[0], valid_feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[0].nodes['A'].data['feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels[0], valid_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_graph_feat(g_feat, time_window):\n",
    "    all_etype_t = sorted(\n",
    "        list(set([etype.split(\"_\")[-1] for _, etype, _ in g_feat.canonical_etypes]))\n",
    "    )\n",
    "\n",
    "    if len(all_etype_t) >= time_window:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(value, fpath, name=None):\n",
    "    with open(fpath, 'a') as fout:\n",
    "        fout.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, svdd, val_feats, val_labels, pred_node_type=\"ALL\"):\n",
    "    val_auc_list, val_ap_list = [], []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (G_feat, G_label) in enumerate(zip(val_feats, val_labels)):\n",
    "            if not valid_graph_feat(G_feat, time_window):\n",
    "                continue\n",
    "            try:\n",
    "                h = model[0](G_feat.to(device), pred_node_type)\n",
    "                f_labels = []\n",
    "                f_pred = []\n",
    "                all_h = []\n",
    "                for ntype in G_label.keys():\n",
    "                    pred = svdd.compute_score(h[ntype]).view(-1, 1)\n",
    "                    label = G_label[ntype].to(device).view(-1, 1)\n",
    "\n",
    "                    label_mask = (label == 0) | (label == 1)\n",
    "\n",
    "                    masked_label = label[label_mask]\n",
    "                    masked_pred = pred[label_mask]\n",
    "\n",
    "                    f_labels.append(masked_label)\n",
    "                    f_pred.append(masked_pred)\n",
    "\n",
    "                f_labels = torch.cat(f_labels)\n",
    "                f_pred = torch.cat(f_pred)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"failed val index: {i}\")\n",
    "                raise Exception(e)\n",
    "\n",
    "            if f_labels.unique().shape[0] >= 2:\n",
    "                # AUC\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(\n",
    "                    f_labels.numpy(), f_pred.numpy()\n",
    "                )\n",
    "                auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "                # AP\n",
    "                precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                    f_labels.numpy(), f_pred.numpy()\n",
    "                )\n",
    "                ap = metrics.auc(recall, precision)\n",
    "\n",
    "                val_auc_list.append(auc)\n",
    "                val_ap_list.append(ap)\n",
    "\n",
    "        auc = sum(val_auc_list) / len(val_auc_list)\n",
    "        ap = sum(val_ap_list) / len(val_ap_list)\n",
    "\n",
    "        print(f\"\\tEval AUC/AP: {auc} / {ap}\")\n",
    "\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_atom = train_feats[10]\n",
    "mae_list, rmse_list = [], []\n",
    "model_out_path = 'checkpoint'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "htgnn = HTGNN(graph=graph_atom, n_inp=16, n_hid=8, n_layers=2, n_heads=1, time_window=time_window, norm=False, device=device).to(device)\n",
    "predictor = NodePredictor(n_inp=8, n_classes=1).to(device)\n",
    "model = nn.Sequential(htgnn, predictor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=True, path=f'{model_out_path}/checkpoint_HTGNN.pt')\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
    "\n",
    "# train_mae_list, train_rmse_list = [], []\n",
    "train_svdd_list = []\n",
    "idx = np.random.permutation(len(train_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDDLoss:\n",
    "    def __init__(self) -> None:\n",
    "        self.center = None\n",
    "        self.l2_lambda = 0.001\n",
    "        self.save_path = \"./results/dgraph_svdd\"\n",
    "\n",
    "    def set_svdd_center(self, center):\n",
    "        self.center = center\n",
    "\n",
    "    def load_svdd_center(self, fpath):\n",
    "        raise Exception(\"Not Implemented!\")\n",
    "\n",
    "    def save_svdd_center(self):\n",
    "        torch.save(self.center, f\"{self.save_path}/SVDD_Center.pt\")\n",
    "\n",
    "    def compute_svdd_loss(self, model, node_embeddings):\n",
    "        if self.center is None:\n",
    "            with torch.no_grad():\n",
    "                center = torch.mean(node_embeddings, 0)\n",
    "                self.set_svdd_center(center)\n",
    "                self.save_svdd_center()\n",
    "\n",
    "        dist = torch.sum(torch.square(node_embeddings - self.center), 1)\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters()) / 2\n",
    "        _loss = torch.mean(dist)\n",
    "\n",
    "        svdd_loss = _loss + self.l2_lambda * l2_norm\n",
    "        return svdd_loss\n",
    "    \n",
    "    def compute_score(self, node_embeddings):\n",
    "        dist = torch.mean(torch.square(node_embeddings - self.center), 1)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 0 ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/821 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch SVDD Loss: 3.101461887359619\n",
      "\tEval AUC/AP: 0.312984496124031 / 0.015126144292616205\n",
      "Validation loss decreased (inf --> 3.101462).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_node_type = \"ALL\"\n",
    "save_path = \"./results/dgraph_svdd\"\n",
    "\n",
    "svdd = SVDDLoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "\n",
    "    print(f\"============ Epoch {epoch} ============\")\n",
    "    for i in tqdm(idx):\n",
    "        G_feat = train_feats[i].to(device)\n",
    "        G_label = train_labels[i]\n",
    "\n",
    "        # check if graph contains more than 2 windows\n",
    "        if not valid_graph_feat(G_feat, time_window):\n",
    "            continue\n",
    "\n",
    "        h = model[0](G_feat, pred_node_type)\n",
    "\n",
    "        all_h = []\n",
    "        f_labels = []\n",
    "        for ntype in G_label.keys():\n",
    "            label = G_label[ntype].to(device).view(-1, 1)\n",
    "\n",
    "            label_mask = (label == 0) | (label == 1)\n",
    "\n",
    "            masked_label = label[label_mask]\n",
    "\n",
    "            f_labels.append(masked_label)\n",
    "            all_h.append(h[ntype])\n",
    "\n",
    "        f_labels = torch.cat(f_labels)\n",
    "        all_h = torch.cat(all_h, 0)\n",
    "\n",
    "        loss = svdd.compute_svdd_loss(model[0], all_h)\n",
    "        train_svdd_list.append(loss.item())\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    epoch_loss = sum(train_svdd_list) / len(train_svdd_list)\n",
    "    print(f\"Epoch SVDD Loss: {epoch_loss}\")\n",
    "\n",
    "    write_to_file(epoch_loss, f\"{save_path}/train_svdd_loss.txt\")\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        auc, ap = evaluate(model, svdd, valid_feats, valid_labels)\n",
    "        write_to_file(auc, f\"{save_path}/eval_auc.txt\")\n",
    "        write_to_file(ap, f\"{save_path}/eval_ap.txt\")\n",
    "        early_stopping(loss, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
